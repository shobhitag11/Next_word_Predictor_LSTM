{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "aousYyFrMBFH"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"TECHNICAL SKILLS\n",
        "Programming languages: Python\n",
        "Statistical tool: SAS, Python\n",
        "Cloud: AWS, GCP\n",
        "Databases/Servers: MySQL, BigQuery\n",
        "Vector DB: FAISS, Milvus, ScaNN\n",
        "Data visualization tools: Tableau, Python\n",
        "DevOps: Git, Docker, Kubernetes\n",
        "OS: Windows, MacOS, RHEL8.x, Ubuntu\n",
        "Distributed Computing: Ray, Seldon\n",
        "CONTACT INFORMATION\n",
        "Address: Antalia Furnished, Sector 122, Noida,\n",
        "UP, India\n",
        "Mobile: +91-987653210\n",
        "Email: shobhitaga.1108@gmail.com\n",
        "PROFILE SUMMARY\n",
        "Senior Data Scientist with 6+ years experience in Python, ML, NLP,\n",
        "Generative AI, LLMs, MLOps, and AI solution Architecture.\n",
        "Expertise in best practices for building software applications integrated\n",
        "with AI, Machine Learning and Generative AI.\n",
        "Expert in advanced ML algorithms, specializing in transformer models.\n",
        "Developed high-performance models, optimizing latency, memory, and\n",
        "throughput.\n",
        "Design, develop, and implement Generative AI models and algorithms, using\n",
        "open-source LLM model families such as Flan, Mosaic, Falcon, Llama2, text-\n",
        "bison and Gemini versions from Googleâ€™s Vertex AI.\n",
        "Experience in LLM model training, deployment, and serving sharded across\n",
        "multi-GPUs on dedicated Nvidia hardware.\n",
        "Experience building MLOps pipeline in GCP using various services like\n",
        "dataflow, big query, data proc, vertexAI etc.\n",
        "HONORS AND AWARDS\n",
        "Incedo: Received the Innovation and\n",
        "Customer Excellence Award on April 13, 2023.\n",
        "Incedo: Honored with the Made a Difference\n",
        "Award on June 3, 2022.\n",
        "FIS: Earned an On-the-Spot Award on\n",
        "December 15, 2020.\n",
        "Mando: Recognized as the Star Performer on\n",
        "December 2, 2019.\n",
        "TCS: Awarded an On-the-Spot Award on\n",
        "February 5, 2019.\n",
        "TCS: Achieved an On-the-Spot Award on\n",
        "October 12, 2018.\n",
        "OBJECTIVE\n",
        "I am committed to continuously enhancing my\n",
        "skills and staying at the forefront of emerging\n",
        "technologies to deliver actionable insights and\n",
        "measurable value through data-driven solutions\n",
        "and experience to make a significant impact on a\n",
        "company's business.\n",
        "SHOBHIT AGARWAL\n",
        "WORK EXPERIENCE\n",
        "Senior Data Scientist (Client- Verizon)\n",
        "Responsible for maintaining end-to-end MLOPs pipeline in the Data & AI\n",
        "department, covering model development and deployment.\n",
        "Utilized GCP services such as Cloud Functions, Dataflow, Pub/Sub,\n",
        "BigQuery, Cloud Storage, GKE, Vertex AI, and Cloud Composer.\n",
        "Developed conversational AI models for text classification, summarization,\n",
        "and text generation using ML/DL.\n",
        "Leveraged the Langchain framework for building applications powered by\n",
        "large language models and integrating proprietary data.\n",
        "Conducted research and experimentation with vector databases like Milvus\n",
        "and FAISS exploring open-source LLM models on multi-GPUs using ray and\n",
        "vLLMs, including high-end GPUs like A100, K80, T4, and A10G etc.\n",
        "Built the RAG-based architecture for open-source LLM models and also built\n",
        "the model fine-tuning pipeline using PEFT, and LoRA.\n",
        "Optimizing the model weights for vLLM-hosted models.\n",
        "Built UI and APIs integrated with Gradio, FastAPI, and streamlit for quick\n",
        "simple web applications\n",
        "Incedo Inc. | Gurgaon | Oct 2021- Present\n",
        "I worked in the Leveraged Products Development department to provide\n",
        "highly advanced product solutions using AI.\n",
        "Created a call recording and monitoring solution with AI-driven analysis for\n",
        "call recordings, agent performance, and customer satisfaction.\n",
        "Developed custom ML models for NLP tasks like sentiment analysis,\n",
        "emotion analysis, profanity detection, call masking, and real-time agent\n",
        "support chatbots.\n",
        "Designed a hybrid emotion analysis model capable of working with both\n",
        "audio and textual data.\n",
        "Implemented ML-based chatbots using RASA to improve cost efficiency and\n",
        "enhance brand perception.\n",
        "Pioneered the development of an in-house speech-to-text (STT) engine from\n",
        "scratch.\n",
        "Lead Development Engineer\n",
        "FIS Global | Gurgaon |Jun 2020 - Oct 2021\n",
        "CERTIFICATIONS\n",
        "Global SAS Certified Base Programmer for\n",
        "SAS 9: Awarded by SAS on September 15,\n",
        "2018.\n",
        "SAS Programming 1: Essentials: Certified by\n",
        "SAS in 2018.\n",
        "Machine Learning (Python) Certification:\n",
        "Received from PST Analytics in 2018.\n",
        "R Programming Certification: Attained from\n",
        "PST Analytics in 2018.\n",
        "Agile Way of Working Foundation:\n",
        "Completed on May 8, 2018, at TCS.\n",
        "Digital: Cloud Computing (General)\n",
        "Foundation: Achieved on May 16, 2018, at\n",
        "TCS.\n",
        "Advanced SAS Certification: Earned from PST\n",
        "Analytics on December 31, 2017.\n",
        "INTERNSHIP\n",
        "Data Analyst- Trainee (Client- Tesco PLC)\n",
        "Ebizon Netinfo Pvt. Ltd. | Noida | Nov 2017 - Feb 2018\n",
        "Analyzing client-provided data.\n",
        "Conducting data preprocessing with both SAS and Tableau.\n",
        "Constructing tailored queries in MySQL for specific data retrieval.\n",
        "Developing interactive KPIs and dynamic dashboards within Tableau.\n",
        "Implementing automation for visualized reports and dashboards in Tableau.\n",
        "EDUCATION\n",
        "SRMSCET, Bareilly, Uttar Pradesh\n",
        "Wood Row School, Bareilly, Uttar Pradesh\n",
        "B.Tech. in CSE (Jul 2013- Jun 2017) with 72%\n",
        "XIIth (Mar 2012- Apr 2013) with 75%\n",
        "Bishop Conrad Sr. Sec. School, Bareilly, Uttar Pradesh\n",
        "Xth (Mar 2010- Apr 2011) with 8.2 CGPA\n",
        "Assistant System Engineer (Client- GE)\n",
        "Facilitated daily Scrum calls with clients to provide updates and ensure\n",
        "alignment.\n",
        "Utilized Python and Tableau to analyze and visualize data.\n",
        "Extracted insights from historical data for predictive analytics.\n",
        "Conducted data cleaning and preprocessing with Python.\n",
        "Employed MySQL and PROC SQL queries in SAS to extract and process data,\n",
        "while also implementing regression models, with data stored on AWS S3 and\n",
        "Redshift for Tableau connectivity.\n",
        "TCS | Kolkata | Mar 2018 - Jun 2019\n",
        "Worked in the Automation team within the CAE department.\n",
        "Automated repetitive tasks and employed Python-based machine\n",
        "learning for 3D model analysis.\n",
        "Conducted FEA and Hypermesh analysis on 3D models.\n",
        "Developed an in-house product for feature identification and meshing in\n",
        "3D models, resulting in annual savings of $0.25 million.\n",
        "Proficient in feature extraction, including holes and fillets, and used\n",
        "Abaqus for 3D model simulation and post-processing.\n",
        "Utilized Python and machine learning techniques for data modelling,\n",
        "cleaning, and synthesizing insights from large-scale databases,\n",
        "facilitating informed decision-making.\n",
        "Mando Softtech | Gurgaon | Jul 2019 - May 2020\n",
        "Associate Engineer\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "ucnv-HjOMNNd"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = text.split(\"\\n\")"
      ],
      "metadata": {
        "id": "J3CrFIAoM4DY"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for sentence in sentences:\n",
        "  print(sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zDcy6m5AM79X",
        "outputId": "bc0d30a8-e651-43ef-c497-f8ccaf638500"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TECHNICAL SKILLS\n",
            "Programming languages: Python\n",
            "Statistical tool: SAS, Python\n",
            "Cloud: AWS, GCP\n",
            "Databases/Servers: MySQL, BigQuery\n",
            "Vector DB: FAISS, Milvus, ScaNN\n",
            "Data visualization tools: Tableau, Python\n",
            "DevOps: Git, Docker, Kubernetes\n",
            "OS: Windows, MacOS, RHEL8.x, Ubuntu\n",
            "Distributed Computing: Ray, Seldon\n",
            "CONTACT INFORMATION\n",
            "Address: Antalia Furnished, Sector 122, Noida,\n",
            "UP, India\n",
            "Mobile: +91-987653210\n",
            "Email: shobhitaga.1108@gmail.com\n",
            "PROFILE SUMMARY\n",
            "Senior Data Scientist with 6+ years experience in Python, ML, NLP,\n",
            "Generative AI, LLMs, MLOps, and AI solution Architecture.\n",
            "Expertise in best practices for building software applications integrated\n",
            "with AI, Machine Learning and Generative AI.\n",
            "Expert in advanced ML algorithms, specializing in transformer models.\n",
            "Developed high-performance models, optimizing latency, memory, and\n",
            "throughput.\n",
            "Design, develop, and implement Generative AI models and algorithms, using\n",
            "open-source LLM model families such as Flan, Mosaic, Falcon, Llama2, text-\n",
            "bison and Gemini versions from Googleâ€™s Vertex AI.\n",
            "Experience in LLM model training, deployment, and serving sharded across\n",
            "multi-GPUs on dedicated Nvidia hardware.\n",
            "Experience building MLOps pipeline in GCP using various services like\n",
            "dataflow, big query, data proc, vertexAI etc.\n",
            "HONORS AND AWARDS\n",
            "Incedo: Received the Innovation and\n",
            "Customer Excellence Award on April 13, 2023.\n",
            "Incedo: Honored with the Made a Difference\n",
            "Award on June 3, 2022.\n",
            "FIS: Earned an On-the-Spot Award on\n",
            "December 15, 2020.\n",
            "Mando: Recognized as the Star Performer on\n",
            "December 2, 2019.\n",
            "TCS: Awarded an On-the-Spot Award on\n",
            "February 5, 2019.\n",
            "TCS: Achieved an On-the-Spot Award on\n",
            "October 12, 2018.\n",
            "OBJECTIVE\n",
            "I am committed to continuously enhancing my\n",
            "skills and staying at the forefront of emerging\n",
            "technologies to deliver actionable insights and\n",
            "measurable value through data-driven solutions\n",
            "and experience to make a significant impact on a\n",
            "company's business.\n",
            "SHOBHIT AGARWAL\n",
            "WORK EXPERIENCE\n",
            "Senior Data Scientist (Client- Verizon)\n",
            "Responsible for maintaining end-to-end MLOPs pipeline in the Data & AI\n",
            "department, covering model development and deployment.\n",
            "Utilized GCP services such as Cloud Functions, Dataflow, Pub/Sub,\n",
            "BigQuery, Cloud Storage, GKE, Vertex AI, and Cloud Composer.\n",
            "Developed conversational AI models for text classification, summarization,\n",
            "and text generation using ML/DL.\n",
            "Leveraged the Langchain framework for building applications powered by\n",
            "large language models and integrating proprietary data.\n",
            "Conducted research and experimentation with vector databases like Milvus\n",
            "and FAISS exploring open-source LLM models on multi-GPUs using ray and\n",
            "vLLMs, including high-end GPUs like A100, K80, T4, and A10G etc.\n",
            "Built the RAG-based architecture for open-source LLM models and also built\n",
            "the model fine-tuning pipeline using PEFT, and LoRA.\n",
            "Optimizing the model weights for vLLM-hosted models.\n",
            "Built UI and APIs integrated with Gradio, FastAPI, and streamlit for quick\n",
            "simple web applications\n",
            "Incedo Inc. | Gurgaon | Oct 2021- Present\n",
            "I worked in the Leveraged Products Development department to provide\n",
            "highly advanced product solutions using AI.\n",
            "Created a call recording and monitoring solution with AI-driven analysis for\n",
            "call recordings, agent performance, and customer satisfaction.\n",
            "Developed custom ML models for NLP tasks like sentiment analysis,\n",
            "emotion analysis, profanity detection, call masking, and real-time agent\n",
            "support chatbots.\n",
            "Designed a hybrid emotion analysis model capable of working with both\n",
            "audio and textual data.\n",
            "Implemented ML-based chatbots using RASA to improve cost efficiency and\n",
            "enhance brand perception.\n",
            "Pioneered the development of an in-house speech-to-text (STT) engine from\n",
            "scratch.\n",
            "Lead Development Engineer\n",
            "FIS Global | Gurgaon |Jun 2020 - Oct 2021\n",
            "CERTIFICATIONS\n",
            "Global SAS Certified Base Programmer for\n",
            "SAS 9: Awarded by SAS on September 15,\n",
            "2018.\n",
            "SAS Programming 1: Essentials: Certified by\n",
            "SAS in 2018.\n",
            "Machine Learning (Python) Certification:\n",
            "Received from PST Analytics in 2018.\n",
            "R Programming Certification: Attained from\n",
            "PST Analytics in 2018.\n",
            "Agile Way of Working Foundation:\n",
            "Completed on May 8, 2018, at TCS.\n",
            "Digital: Cloud Computing (General)\n",
            "Foundation: Achieved on May 16, 2018, at\n",
            "TCS.\n",
            "Advanced SAS Certification: Earned from PST\n",
            "Analytics on December 31, 2017.\n",
            "INTERNSHIP\n",
            "Data Analyst- Trainee (Client- Tesco PLC)\n",
            "Ebizon Netinfo Pvt. Ltd. | Noida | Nov 2017 - Feb 2018\n",
            "Analyzing client-provided data.\n",
            "Conducting data preprocessing with both SAS and Tableau.\n",
            "Constructing tailored queries in MySQL for specific data retrieval.\n",
            "Developing interactive KPIs and dynamic dashboards within Tableau.\n",
            "Implementing automation for visualized reports and dashboards in Tableau.\n",
            "EDUCATION\n",
            "SRMSCET, Bareilly, Uttar Pradesh\n",
            "Wood Row School, Bareilly, Uttar Pradesh\n",
            "B.Tech. in CSE (Jul 2013- Jun 2017) with 72%\n",
            "XIIth (Mar 2012- Apr 2013) with 75%\n",
            "Bishop Conrad Sr. Sec. School, Bareilly, Uttar Pradesh\n",
            "Xth (Mar 2010- Apr 2011) with 8.2 CGPA\n",
            "Assistant System Engineer (Client- GE)\n",
            "Facilitated daily Scrum calls with clients to provide updates and ensure\n",
            "alignment.\n",
            "Utilized Python and Tableau to analyze and visualize data.\n",
            "Extracted insights from historical data for predictive analytics.\n",
            "Conducted data cleaning and preprocessing with Python.\n",
            "Employed MySQL and PROC SQL queries in SAS to extract and process data,\n",
            "while also implementing regression models, with data stored on AWS S3 and\n",
            "Redshift for Tableau connectivity.\n",
            "TCS | Kolkata | Mar 2018 - Jun 2019\n",
            "Worked in the Automation team within the CAE department.\n",
            "Automated repetitive tasks and employed Python-based machine\n",
            "learning for 3D model analysis.\n",
            "Conducted FEA and Hypermesh analysis on 3D models.\n",
            "Developed an in-house product for feature identification and meshing in\n",
            "3D models, resulting in annual savings of $0.25 million.\n",
            "Proficient in feature extraction, including holes and fillets, and used\n",
            "Abaqus for 3D model simulation and post-processing.\n",
            "Utilized Python and machine learning techniques for data modelling,\n",
            "cleaning, and synthesizing insights from large-scale databases,\n",
            "facilitating informed decision-making.\n",
            "Mando Softtech | Gurgaon | Jul 2019 - May 2020\n",
            "Associate Engineer\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ],
      "metadata": {
        "id": "u91VLB-zM-_5"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()"
      ],
      "metadata": {
        "id": "e3ixsKcKNuv_"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.fit_on_texts([text])"
      ],
      "metadata": {
        "id": "vpDPXfTFOIjG"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(tokenizer.word_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E7Z1NGzDOS1C",
        "outputId": "c6a8715b-4706-451d-80ef-848229cc99b7"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "466"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.word_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2hx8Poxmhb4h",
        "outputId": "0fe16a79-5bcd-48e7-977d-d3f4217dc64a"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'and': 1,\n",
              " 'in': 2,\n",
              " 'data': 3,\n",
              " 'for': 4,\n",
              " 'on': 5,\n",
              " 'the': 6,\n",
              " 'with': 7,\n",
              " 'models': 8,\n",
              " 'ai': 9,\n",
              " 'to': 10,\n",
              " 'python': 11,\n",
              " 'sas': 12,\n",
              " '2018': 13,\n",
              " 'model': 14,\n",
              " 'using': 15,\n",
              " 'from': 16,\n",
              " 'tableau': 17,\n",
              " 'analysis': 18,\n",
              " 'cloud': 19,\n",
              " 'experience': 20,\n",
              " 'ml': 21,\n",
              " 'award': 22,\n",
              " 'a': 23,\n",
              " 'an': 24,\n",
              " 'tcs': 25,\n",
              " 'of': 26,\n",
              " 'machine': 27,\n",
              " 'learning': 28,\n",
              " 'developed': 29,\n",
              " 'llm': 30,\n",
              " 'text': 31,\n",
              " 'like': 32,\n",
              " '2019': 33,\n",
              " 'client': 34,\n",
              " 'development': 35,\n",
              " 'analytics': 36,\n",
              " '3d': 37,\n",
              " 'programming': 38,\n",
              " 'gcp': 39,\n",
              " 'databases': 40,\n",
              " 'mysql': 41,\n",
              " 'generative': 42,\n",
              " 'mlops': 43,\n",
              " 'building': 44,\n",
              " 'applications': 45,\n",
              " 'advanced': 46,\n",
              " 'open': 47,\n",
              " 'source': 48,\n",
              " 'as': 49,\n",
              " 'gpus': 50,\n",
              " 'pipeline': 51,\n",
              " 'incedo': 52,\n",
              " 'spot': 53,\n",
              " 'december': 54,\n",
              " '2020': 55,\n",
              " 'at': 56,\n",
              " 'insights': 57,\n",
              " 'end': 58,\n",
              " 'department': 59,\n",
              " 'utilized': 60,\n",
              " 'by': 61,\n",
              " 'conducted': 62,\n",
              " 'built': 63,\n",
              " 'based': 64,\n",
              " 'gurgaon': 65,\n",
              " 'call': 66,\n",
              " 'engineer': 67,\n",
              " 'jun': 68,\n",
              " 'certification': 69,\n",
              " 'pst': 70,\n",
              " 'may': 71,\n",
              " '2017': 72,\n",
              " 'bareilly': 73,\n",
              " 'uttar': 74,\n",
              " 'pradesh': 75,\n",
              " 'mar': 76,\n",
              " 'skills': 77,\n",
              " 'aws': 78,\n",
              " 'bigquery': 79,\n",
              " 'vector': 80,\n",
              " 'faiss': 81,\n",
              " 'milvus': 82,\n",
              " 'computing': 83,\n",
              " 'ray': 84,\n",
              " 'noida': 85,\n",
              " 'senior': 86,\n",
              " 'scientist': 87,\n",
              " 'nlp': 88,\n",
              " 'solution': 89,\n",
              " 'architecture': 90,\n",
              " 'integrated': 91,\n",
              " 'algorithms': 92,\n",
              " 'high': 93,\n",
              " 'performance': 94,\n",
              " 'optimizing': 95,\n",
              " 'such': 96,\n",
              " 'vertex': 97,\n",
              " 'deployment': 98,\n",
              " 'multi': 99,\n",
              " 'services': 100,\n",
              " 'dataflow': 101,\n",
              " 'proc': 102,\n",
              " 'etc': 103,\n",
              " 'received': 104,\n",
              " 'customer': 105,\n",
              " 'fis': 106,\n",
              " 'earned': 107,\n",
              " '15': 108,\n",
              " 'mando': 109,\n",
              " '2': 110,\n",
              " 'awarded': 111,\n",
              " 'achieved': 112,\n",
              " 'i': 113,\n",
              " 'driven': 114,\n",
              " 'solutions': 115,\n",
              " 'leveraged': 116,\n",
              " 'large': 117,\n",
              " 'including': 118,\n",
              " 'also': 119,\n",
              " 'oct': 120,\n",
              " '2021': 121,\n",
              " 'worked': 122,\n",
              " 'provide': 123,\n",
              " 'product': 124,\n",
              " 'agent': 125,\n",
              " 'tasks': 126,\n",
              " 'emotion': 127,\n",
              " 'chatbots': 128,\n",
              " 'working': 129,\n",
              " 'both': 130,\n",
              " 'house': 131,\n",
              " 'global': 132,\n",
              " 'certified': 133,\n",
              " 'foundation': 134,\n",
              " '8': 135,\n",
              " 'preprocessing': 136,\n",
              " 'queries': 137,\n",
              " 'dashboards': 138,\n",
              " 'within': 139,\n",
              " 'implementing': 140,\n",
              " 'automation': 141,\n",
              " 'school': 142,\n",
              " 'jul': 143,\n",
              " '2013': 144,\n",
              " 'apr': 145,\n",
              " 'cleaning': 146,\n",
              " 'employed': 147,\n",
              " 'feature': 148,\n",
              " 'technical': 149,\n",
              " 'languages': 150,\n",
              " 'statistical': 151,\n",
              " 'tool': 152,\n",
              " 'servers': 153,\n",
              " 'db': 154,\n",
              " 'scann': 155,\n",
              " 'visualization': 156,\n",
              " 'tools': 157,\n",
              " 'devops': 158,\n",
              " 'git': 159,\n",
              " 'docker': 160,\n",
              " 'kubernetes': 161,\n",
              " 'os': 162,\n",
              " 'windows': 163,\n",
              " 'macos': 164,\n",
              " 'rhel8': 165,\n",
              " 'x': 166,\n",
              " 'ubuntu': 167,\n",
              " 'distributed': 168,\n",
              " 'seldon': 169,\n",
              " 'contact': 170,\n",
              " 'information': 171,\n",
              " 'address': 172,\n",
              " 'antalia': 173,\n",
              " 'furnished': 174,\n",
              " 'sector': 175,\n",
              " '122': 176,\n",
              " 'up': 177,\n",
              " 'india': 178,\n",
              " 'mobile': 179,\n",
              " '91': 180,\n",
              " '987653210': 181,\n",
              " 'email': 182,\n",
              " 'shobhitaga': 183,\n",
              " '1108': 184,\n",
              " 'gmail': 185,\n",
              " 'com': 186,\n",
              " 'profile': 187,\n",
              " 'summary': 188,\n",
              " '6': 189,\n",
              " 'years': 190,\n",
              " 'llms': 191,\n",
              " 'expertise': 192,\n",
              " 'best': 193,\n",
              " 'practices': 194,\n",
              " 'software': 195,\n",
              " 'expert': 196,\n",
              " 'specializing': 197,\n",
              " 'transformer': 198,\n",
              " 'latency': 199,\n",
              " 'memory': 200,\n",
              " 'throughput': 201,\n",
              " 'design': 202,\n",
              " 'develop': 203,\n",
              " 'implement': 204,\n",
              " 'families': 205,\n",
              " 'flan': 206,\n",
              " 'mosaic': 207,\n",
              " 'falcon': 208,\n",
              " 'llama2': 209,\n",
              " 'bison': 210,\n",
              " 'gemini': 211,\n",
              " 'versions': 212,\n",
              " 'googleâ€™s': 213,\n",
              " 'training': 214,\n",
              " 'serving': 215,\n",
              " 'sharded': 216,\n",
              " 'across': 217,\n",
              " 'dedicated': 218,\n",
              " 'nvidia': 219,\n",
              " 'hardware': 220,\n",
              " 'various': 221,\n",
              " 'big': 222,\n",
              " 'query': 223,\n",
              " 'vertexai': 224,\n",
              " 'honors': 225,\n",
              " 'awards': 226,\n",
              " 'innovation': 227,\n",
              " 'excellence': 228,\n",
              " 'april': 229,\n",
              " '13': 230,\n",
              " '2023': 231,\n",
              " 'honored': 232,\n",
              " 'made': 233,\n",
              " 'difference': 234,\n",
              " 'june': 235,\n",
              " '3': 236,\n",
              " '2022': 237,\n",
              " 'recognized': 238,\n",
              " 'star': 239,\n",
              " 'performer': 240,\n",
              " 'february': 241,\n",
              " '5': 242,\n",
              " 'october': 243,\n",
              " '12': 244,\n",
              " 'objective': 245,\n",
              " 'am': 246,\n",
              " 'committed': 247,\n",
              " 'continuously': 248,\n",
              " 'enhancing': 249,\n",
              " 'my': 250,\n",
              " 'staying': 251,\n",
              " 'forefront': 252,\n",
              " 'emerging': 253,\n",
              " 'technologies': 254,\n",
              " 'deliver': 255,\n",
              " 'actionable': 256,\n",
              " 'measurable': 257,\n",
              " 'value': 258,\n",
              " 'through': 259,\n",
              " 'make': 260,\n",
              " 'significant': 261,\n",
              " 'impact': 262,\n",
              " \"company's\": 263,\n",
              " 'business': 264,\n",
              " 'shobhit': 265,\n",
              " 'agarwal': 266,\n",
              " 'work': 267,\n",
              " 'verizon': 268,\n",
              " 'responsible': 269,\n",
              " 'maintaining': 270,\n",
              " 'covering': 271,\n",
              " 'functions': 272,\n",
              " 'pub': 273,\n",
              " 'sub': 274,\n",
              " 'storage': 275,\n",
              " 'gke': 276,\n",
              " 'composer': 277,\n",
              " 'conversational': 278,\n",
              " 'classification': 279,\n",
              " 'summarization': 280,\n",
              " 'generation': 281,\n",
              " 'dl': 282,\n",
              " 'langchain': 283,\n",
              " 'framework': 284,\n",
              " 'powered': 285,\n",
              " 'language': 286,\n",
              " 'integrating': 287,\n",
              " 'proprietary': 288,\n",
              " 'research': 289,\n",
              " 'experimentation': 290,\n",
              " 'exploring': 291,\n",
              " 'vllms': 292,\n",
              " 'a100': 293,\n",
              " 'k80': 294,\n",
              " 't4': 295,\n",
              " 'a10g': 296,\n",
              " 'rag': 297,\n",
              " 'fine': 298,\n",
              " 'tuning': 299,\n",
              " 'peft': 300,\n",
              " 'lora': 301,\n",
              " 'weights': 302,\n",
              " 'vllm': 303,\n",
              " 'hosted': 304,\n",
              " 'ui': 305,\n",
              " 'apis': 306,\n",
              " 'gradio': 307,\n",
              " 'fastapi': 308,\n",
              " 'streamlit': 309,\n",
              " 'quick': 310,\n",
              " 'simple': 311,\n",
              " 'web': 312,\n",
              " 'inc': 313,\n",
              " 'present': 314,\n",
              " 'products': 315,\n",
              " 'highly': 316,\n",
              " 'created': 317,\n",
              " 'recording': 318,\n",
              " 'monitoring': 319,\n",
              " 'recordings': 320,\n",
              " 'satisfaction': 321,\n",
              " 'custom': 322,\n",
              " 'sentiment': 323,\n",
              " 'profanity': 324,\n",
              " 'detection': 325,\n",
              " 'masking': 326,\n",
              " 'real': 327,\n",
              " 'time': 328,\n",
              " 'support': 329,\n",
              " 'designed': 330,\n",
              " 'hybrid': 331,\n",
              " 'capable': 332,\n",
              " 'audio': 333,\n",
              " 'textual': 334,\n",
              " 'implemented': 335,\n",
              " 'rasa': 336,\n",
              " 'improve': 337,\n",
              " 'cost': 338,\n",
              " 'efficiency': 339,\n",
              " 'enhance': 340,\n",
              " 'brand': 341,\n",
              " 'perception': 342,\n",
              " 'pioneered': 343,\n",
              " 'speech': 344,\n",
              " 'stt': 345,\n",
              " 'engine': 346,\n",
              " 'scratch': 347,\n",
              " 'lead': 348,\n",
              " 'certifications': 349,\n",
              " 'base': 350,\n",
              " 'programmer': 351,\n",
              " '9': 352,\n",
              " 'september': 353,\n",
              " '1': 354,\n",
              " 'essentials': 355,\n",
              " 'r': 356,\n",
              " 'attained': 357,\n",
              " 'agile': 358,\n",
              " 'way': 359,\n",
              " 'completed': 360,\n",
              " 'digital': 361,\n",
              " 'general': 362,\n",
              " '16': 363,\n",
              " '31': 364,\n",
              " 'internship': 365,\n",
              " 'analyst': 366,\n",
              " 'trainee': 367,\n",
              " 'tesco': 368,\n",
              " 'plc': 369,\n",
              " 'ebizon': 370,\n",
              " 'netinfo': 371,\n",
              " 'pvt': 372,\n",
              " 'ltd': 373,\n",
              " 'nov': 374,\n",
              " 'feb': 375,\n",
              " 'analyzing': 376,\n",
              " 'provided': 377,\n",
              " 'conducting': 378,\n",
              " 'constructing': 379,\n",
              " 'tailored': 380,\n",
              " 'specific': 381,\n",
              " 'retrieval': 382,\n",
              " 'developing': 383,\n",
              " 'interactive': 384,\n",
              " 'kpis': 385,\n",
              " 'dynamic': 386,\n",
              " 'visualized': 387,\n",
              " 'reports': 388,\n",
              " 'education': 389,\n",
              " 'srmscet': 390,\n",
              " 'wood': 391,\n",
              " 'row': 392,\n",
              " 'b': 393,\n",
              " 'tech': 394,\n",
              " 'cse': 395,\n",
              " '72': 396,\n",
              " 'xiith': 397,\n",
              " '2012': 398,\n",
              " '75': 399,\n",
              " 'bishop': 400,\n",
              " 'conrad': 401,\n",
              " 'sr': 402,\n",
              " 'sec': 403,\n",
              " 'xth': 404,\n",
              " '2010': 405,\n",
              " '2011': 406,\n",
              " 'cgpa': 407,\n",
              " 'assistant': 408,\n",
              " 'system': 409,\n",
              " 'ge': 410,\n",
              " 'facilitated': 411,\n",
              " 'daily': 412,\n",
              " 'scrum': 413,\n",
              " 'calls': 414,\n",
              " 'clients': 415,\n",
              " 'updates': 416,\n",
              " 'ensure': 417,\n",
              " 'alignment': 418,\n",
              " 'analyze': 419,\n",
              " 'visualize': 420,\n",
              " 'extracted': 421,\n",
              " 'historical': 422,\n",
              " 'predictive': 423,\n",
              " 'sql': 424,\n",
              " 'extract': 425,\n",
              " 'process': 426,\n",
              " 'while': 427,\n",
              " 'regression': 428,\n",
              " 'stored': 429,\n",
              " 's3': 430,\n",
              " 'redshift': 431,\n",
              " 'connectivity': 432,\n",
              " 'kolkata': 433,\n",
              " 'team': 434,\n",
              " 'cae': 435,\n",
              " 'automated': 436,\n",
              " 'repetitive': 437,\n",
              " 'fea': 438,\n",
              " 'hypermesh': 439,\n",
              " 'identification': 440,\n",
              " 'meshing': 441,\n",
              " 'resulting': 442,\n",
              " 'annual': 443,\n",
              " 'savings': 444,\n",
              " '0': 445,\n",
              " '25': 446,\n",
              " 'million': 447,\n",
              " 'proficient': 448,\n",
              " 'extraction': 449,\n",
              " 'holes': 450,\n",
              " 'fillets': 451,\n",
              " 'used': 452,\n",
              " 'abaqus': 453,\n",
              " 'simulation': 454,\n",
              " 'post': 455,\n",
              " 'processing': 456,\n",
              " 'techniques': 457,\n",
              " 'modelling': 458,\n",
              " 'synthesizing': 459,\n",
              " 'scale': 460,\n",
              " 'facilitating': 461,\n",
              " 'informed': 462,\n",
              " 'decision': 463,\n",
              " 'making': 464,\n",
              " 'softtech': 465,\n",
              " 'associate': 466}"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences = []\n",
        "# label_sequences = []\n",
        "for sentence in text.split(\"\\n\"):\n",
        "  tokenized_sentence = tokenizer.texts_to_sequences([sentence])[0]\n",
        "\n",
        "  for i in range(1, len(tokenized_sentence)):\n",
        "    input_sequences.append(tokenized_sentence[:i+1])\n",
        "    # label_sequences.append(tokenized_sentence[:-1])"
      ],
      "metadata": {
        "id": "u7Ml360KOVjL"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences"
      ],
      "metadata": {
        "id": "1ZAmc9K6O18N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_len"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zkPTTPOJgYPm",
        "outputId": "bff1531b-2aac-4136-97f0-b6d794bd35b9"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "l_list = []\n",
        "for i in input_sequences:\n",
        "  l_list.append(len(i))\n",
        "max_len = max(l_list)"
      ],
      "metadata": {
        "id": "HJSMQQ3CcZWe"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "pxfqPr65c73z"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "padded_sequences = pad_sequences(input_sequences, maxlen=max_len, padding=\"pre\")"
      ],
      "metadata": {
        "id": "PTJJfYHadE7V"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = padded_sequences[:,:-1]\n",
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ojsxd26kdPKT",
        "outputId": "306af265-8b04-4ecf-a649-b44001f24000"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0, ...,   0,   0, 149],\n",
              "       [  0,   0,   0, ...,   0,   0,  38],\n",
              "       [  0,   0,   0, ...,   0,  38, 150],\n",
              "       ...,\n",
              "       [  0,   0,   0, ...,  65, 143,  33],\n",
              "       [  0,   0,   0, ..., 143,  33,  71],\n",
              "       [  0,   0,   0, ...,   0,   0, 466]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = padded_sequences[:,-1]\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWkTB5ecdqYR",
        "outputId": "5765e3e3-0e4a-46f2-d12c-ddd1d807ac71"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 77, 150,  11, 152,  12,  11,  78,  39, 153,  41,  79, 154,  81,\n",
              "        82, 155, 156, 157,  17,  11, 159, 160, 161, 163, 164, 165, 166,\n",
              "       167,  83,  84, 169, 171, 173, 174, 175, 176,  85, 178, 180, 181,\n",
              "       183, 184, 185, 186, 188,   3,  87,   7, 189, 190,  20,   2,  11,\n",
              "        21,  88,   9, 191,  43,   1,   9,  89,  90,   2, 193, 194,   4,\n",
              "        44, 195,  45,  91,   9,  27,  28,   1,  42,   9,   2,  46,  21,\n",
              "        92, 197,   2, 198,   8,  93,  94,   8,  95, 199, 200,   1, 203,\n",
              "         1, 204,  42,   9,   8,   1,  92,  15,  48,  30,  14, 205,  96,\n",
              "        49, 206, 207, 208, 209,  31,   1, 211, 212,  16, 213,  97,   9,\n",
              "         2,  30,  14, 214,  98,   1, 215, 216, 217,  50,   5, 218, 219,\n",
              "       220,  44,  43,  51,   2,  39,  15, 221, 100,  32, 222, 223,   3,\n",
              "       102, 224, 103,   1, 226, 104,   6, 227,   1, 228,  22,   5, 229,\n",
              "       230, 231, 232,   7,   6, 233,  23, 234,   5, 235, 236, 237, 107,\n",
              "        24,   5,   6,  53,  22,   5, 108,  55, 238,  49,   6, 239, 240,\n",
              "         5, 110,  33, 111,  24,   5,   6,  53,  22,   5, 242,  33, 112,\n",
              "        24,   5,   6,  53,  22,   5, 244,  13, 246, 247,  10, 248, 249,\n",
              "       250,   1, 251,  56,   6, 252,  26, 253,  10, 255, 256,  57,   1,\n",
              "       258, 259,   3, 114, 115,  20,  10, 260,  23, 261, 262,   5,  23,\n",
              "       264, 266,  20,   3,  87,  34, 268,   4, 270,  58,  10,  58,  43,\n",
              "        51,   2,   6,   3,   9, 271,  14,  35,   1,  98,  39, 100,  96,\n",
              "        49,  19, 272, 101, 273, 274,  19, 275, 276,  97,   9,   1,  19,\n",
              "       277, 278,   9,   8,   4,  31, 279, 280,  31, 281,  15,  21, 282,\n",
              "         6, 283, 284,   4,  44,  45, 285,  61, 286,   8,   1, 287, 288,\n",
              "         3, 289,   1, 290,   7,  80,  40,  32,  82,  81, 291,  47,  48,\n",
              "        30,   8,   5,  99,  50,  15,  84,   1, 118,  93,  58,  50,  32,\n",
              "       293, 294, 295,   1, 296, 103,   6, 297,  64,  90,   4,  47,  48,\n",
              "        30,   8,   1, 119,  63,  14, 298, 299,  51,  15, 300,   1, 301,\n",
              "         6,  14, 302,   4, 303, 304,   8, 305,   1, 306,  91,   7, 307,\n",
              "       308,   1, 309,   4, 310, 312,  45, 313,  65, 120, 121, 314, 122,\n",
              "         2,   6, 116, 315,  35,  59,  10, 123,  46, 124, 115,  15,   9,\n",
              "        23,  66, 318,   1, 319,  89,   7,   9, 114,  18,   4, 320, 125,\n",
              "        94,   1, 105, 321, 322,  21,   8,   4,  88, 126,  32, 323,  18,\n",
              "        18, 324, 325,  66, 326,   1, 327, 328, 125, 128,  23, 331, 127,\n",
              "        18,  14, 332,  26, 129,   7, 130,   1, 334,   3,  21,  64, 128,\n",
              "        15, 336,  10, 337, 338, 339,   1, 341, 342,   6,  35,  26,  24,\n",
              "         2, 131, 344,  10,  31, 345, 346,  16,  35,  67, 132,  65,  68,\n",
              "        55, 120, 121,  12, 133, 350, 351,   4, 352, 111,  61,  12,   5,\n",
              "       353, 108,  38, 354, 355, 133,  61,   2,  13,  28,  11,  69,  16,\n",
              "        70,  36,   2,  13,  38,  69, 357,  16,  36,   2,  13, 359,  26,\n",
              "       129, 134,   5,  71, 135,  13,  56,  25,  19,  83, 362, 112,   5,\n",
              "        71, 363,  13,  56,  12,  69, 107,  16,  70,   5,  54, 364,  72,\n",
              "       366, 367,  34, 368, 369, 371, 372, 373,  85, 374,  72, 375,  13,\n",
              "        34, 377,   3,   3, 136,   7, 130,  12,   1,  17, 380, 137,   2,\n",
              "        41,   4, 381,   3, 382, 384, 385,   1, 386, 138, 139,  17, 141,\n",
              "         4, 387, 388,   1, 138,   2,  17,  73,  74,  75, 392, 142,  73,\n",
              "        74,  75, 394,   2, 395, 143, 144,  68,  72,   7, 396,  76, 398,\n",
              "       145, 144,   7, 399, 401, 402, 403, 142,  73,  74,  75,  76, 405,\n",
              "       145, 406,   7, 135, 110, 407, 409,  67,  34, 410, 412, 413, 414,\n",
              "         7, 415,  10, 123, 416,   1, 417,  11,   1,  17,  10, 419,   1,\n",
              "       420,   3,  57,  16, 422,   3,   4, 423,  36,   3, 146,   1, 136,\n",
              "         7,  11,  41,   1, 102, 424, 137,   2,  12,  10, 425,   1, 426,\n",
              "         3, 119, 140, 428,   8,   7,   3, 429,   5,  78, 430,   1,   4,\n",
              "        17, 432, 433,  76,  13,  68,  33,   2,   6, 141, 434, 139,   6,\n",
              "       435,  59, 437, 126,   1, 147,  11,  64,  27,   4,  37,  14,  18,\n",
              "       438,   1, 439,  18,   5,  37,   8,  24,   2, 131, 124,   4, 148,\n",
              "       440,   1, 441,   2,   8, 442,   2, 443, 444,  26, 445, 446, 447,\n",
              "         2, 148, 449, 118, 450,   1, 451,   1, 452,   4,  37,  14, 454,\n",
              "         1, 455, 456,  11,   1,  27,  28, 457,   4,   3, 458,   1, 459,\n",
              "        57,  16, 117, 460,  40, 462, 463, 464, 465,  65, 143,  33,  71,\n",
              "        55,  67], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0FIzi1Iddw7k",
        "outputId": "5025c1f4-b7d1-454c-e07c-84b9b8cd0707"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(769, 12)"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fmBJfn84eCQw",
        "outputId": "e67e1d43-c795-4830-df06-c515bdbb277a"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(769,)"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# num_classes -> Total number of unique words in out tokenizer.word_index, since it starts from 1, num_classes will be 467 instead of 466"
      ],
      "metadata": {
        "id": "tGMJyheDeZln"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y = to_categorical(y, num_classes=467)"
      ],
      "metadata": {
        "id": "yQ7nWM8YeC_d"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xGxfT8GReipK",
        "outputId": "8a2e6081-428d-48c3-b6c0-e87cc2bdc658"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(769, 467)"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# X is input, y is output"
      ],
      "metadata": {
        "id": "vgqJnveve4Hc"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Embedding"
      ],
      "metadata": {
        "id": "KSAGWMY6fHeL"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(467, 100, input_length=12))\n",
        "model.add(LSTM(150))\n",
        "model.add(Dense(467, activation=\"softmax\"))"
      ],
      "metadata": {
        "id": "Wa8yLdOefTWz"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "9_MeeNfnfWwk"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ARVuBuIjf9bm",
        "outputId": "b469ff9f-7682-44d6-e477-6d95166bd39f"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     (None, 12, 100)           46700     \n",
            "                                                                 \n",
            " lstm_3 (LSTM)               (None, 150)               150600    \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 467)               70517     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 267817 (1.02 MB)\n",
            "Trainable params: 267817 (1.02 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X,y, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uvFULjSbf_yG",
        "outputId": "c68529d3-c7a0-410c-c23a-48785978da33"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "25/25 [==============================] - 3s 36ms/step - loss: 6.0886 - accuracy: 0.0377\n",
            "Epoch 2/100\n",
            "25/25 [==============================] - 1s 48ms/step - loss: 5.7028 - accuracy: 0.0572\n",
            "Epoch 3/100\n",
            "25/25 [==============================] - 1s 41ms/step - loss: 5.5685 - accuracy: 0.0572\n",
            "Epoch 4/100\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 5.5281 - accuracy: 0.0572\n",
            "Epoch 5/100\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 5.5055 - accuracy: 0.0572\n",
            "Epoch 6/100\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 5.4840 - accuracy: 0.0572\n",
            "Epoch 7/100\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 5.4457 - accuracy: 0.0572\n",
            "Epoch 8/100\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 5.3993 - accuracy: 0.0572\n",
            "Epoch 9/100\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 5.3150 - accuracy: 0.0637\n",
            "Epoch 10/100\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 5.2335 - accuracy: 0.0663\n",
            "Epoch 11/100\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 5.0974 - accuracy: 0.0871\n",
            "Epoch 12/100\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 4.9567 - accuracy: 0.0845\n",
            "Epoch 13/100\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 4.8134 - accuracy: 0.0923\n",
            "Epoch 14/100\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 4.6630 - accuracy: 0.1027\n",
            "Epoch 15/100\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 4.4811 - accuracy: 0.1287\n",
            "Epoch 16/100\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 4.3011 - accuracy: 0.1456\n",
            "Epoch 17/100\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 4.1385 - accuracy: 0.1638\n",
            "Epoch 18/100\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 3.9634 - accuracy: 0.1808\n",
            "Epoch 19/100\n",
            "25/25 [==============================] - 1s 36ms/step - loss: 3.7975 - accuracy: 0.1912\n",
            "Epoch 20/100\n",
            "25/25 [==============================] - 1s 48ms/step - loss: 3.6251 - accuracy: 0.2497\n",
            "Epoch 21/100\n",
            "25/25 [==============================] - 1s 36ms/step - loss: 3.4886 - accuracy: 0.2614\n",
            "Epoch 22/100\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 3.2878 - accuracy: 0.3108\n",
            "Epoch 23/100\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 3.1347 - accuracy: 0.3368\n",
            "Epoch 24/100\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 2.9630 - accuracy: 0.3849\n",
            "Epoch 25/100\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 2.7963 - accuracy: 0.4174\n",
            "Epoch 26/100\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 2.6556 - accuracy: 0.4603\n",
            "Epoch 27/100\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 2.5035 - accuracy: 0.5098\n",
            "Epoch 28/100\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 2.3739 - accuracy: 0.5605\n",
            "Epoch 29/100\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 2.2632 - accuracy: 0.5995\n",
            "Epoch 30/100\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 2.1487 - accuracy: 0.6164\n",
            "Epoch 31/100\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 2.0078 - accuracy: 0.6489\n",
            "Epoch 32/100\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 1.8800 - accuracy: 0.7100\n",
            "Epoch 33/100\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 1.7767 - accuracy: 0.7399\n",
            "Epoch 34/100\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 1.6584 - accuracy: 0.7659\n",
            "Epoch 35/100\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 1.5407 - accuracy: 0.7984\n",
            "Epoch 36/100\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 1.4524 - accuracy: 0.8166\n",
            "Epoch 37/100\n",
            "25/25 [==============================] - 1s 34ms/step - loss: 1.3883 - accuracy: 0.8427\n",
            "Epoch 38/100\n",
            "25/25 [==============================] - 1s 48ms/step - loss: 1.2915 - accuracy: 0.8427\n",
            "Epoch 39/100\n",
            "25/25 [==============================] - 1s 40ms/step - loss: 1.2165 - accuracy: 0.8518\n",
            "Epoch 40/100\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 1.1381 - accuracy: 0.8674\n",
            "Epoch 41/100\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 1.0629 - accuracy: 0.8778\n",
            "Epoch 42/100\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 1.0380 - accuracy: 0.8973\n",
            "Epoch 43/100\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.9600 - accuracy: 0.8973\n",
            "Epoch 44/100\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.8972 - accuracy: 0.9012\n",
            "Epoch 45/100\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.8355 - accuracy: 0.9168\n",
            "Epoch 46/100\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.7971 - accuracy: 0.9207\n",
            "Epoch 47/100\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.7575 - accuracy: 0.9311\n",
            "Epoch 48/100\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.6922 - accuracy: 0.9324\n",
            "Epoch 49/100\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 0.6863 - accuracy: 0.9337\n",
            "Epoch 50/100\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.6321 - accuracy: 0.9415\n",
            "Epoch 51/100\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.5956 - accuracy: 0.9415\n",
            "Epoch 52/100\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 0.5574 - accuracy: 0.9493\n",
            "Epoch 53/100\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.5264 - accuracy: 0.9441\n",
            "Epoch 54/100\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.4987 - accuracy: 0.9480\n",
            "Epoch 55/100\n",
            "25/25 [==============================] - 1s 40ms/step - loss: 0.4857 - accuracy: 0.9467\n",
            "Epoch 56/100\n",
            "25/25 [==============================] - 1s 44ms/step - loss: 0.4511 - accuracy: 0.9571\n",
            "Epoch 57/100\n",
            "25/25 [==============================] - 1s 36ms/step - loss: 0.4301 - accuracy: 0.9532\n",
            "Epoch 58/100\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.4025 - accuracy: 0.9545\n",
            "Epoch 59/100\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 0.3884 - accuracy: 0.9545\n",
            "Epoch 60/100\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 0.3666 - accuracy: 0.9532\n",
            "Epoch 61/100\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.3492 - accuracy: 0.9571\n",
            "Epoch 62/100\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.3900 - accuracy: 0.9571\n",
            "Epoch 63/100\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.3305 - accuracy: 0.9597\n",
            "Epoch 64/100\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 0.3043 - accuracy: 0.9610\n",
            "Epoch 65/100\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 0.2977 - accuracy: 0.9597\n",
            "Epoch 66/100\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.2795 - accuracy: 0.9597\n",
            "Epoch 67/100\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 0.2777 - accuracy: 0.9584\n",
            "Epoch 68/100\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 0.2768 - accuracy: 0.9623\n",
            "Epoch 69/100\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.2576 - accuracy: 0.9584\n",
            "Epoch 70/100\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.2445 - accuracy: 0.9636\n",
            "Epoch 71/100\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 0.2338 - accuracy: 0.9662\n",
            "Epoch 72/100\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.2242 - accuracy: 0.9610\n",
            "Epoch 73/100\n",
            "25/25 [==============================] - 1s 43ms/step - loss: 0.2266 - accuracy: 0.9675\n",
            "Epoch 74/100\n",
            "25/25 [==============================] - 1s 46ms/step - loss: 0.2163 - accuracy: 0.9610\n",
            "Epoch 75/100\n",
            "25/25 [==============================] - 1s 32ms/step - loss: 0.2036 - accuracy: 0.9610\n",
            "Epoch 76/100\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 0.1963 - accuracy: 0.9636\n",
            "Epoch 77/100\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 0.1912 - accuracy: 0.9610\n",
            "Epoch 78/100\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.1845 - accuracy: 0.9636\n",
            "Epoch 79/100\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.1847 - accuracy: 0.9584\n",
            "Epoch 80/100\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 0.1774 - accuracy: 0.9636\n",
            "Epoch 81/100\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 0.1736 - accuracy: 0.9623\n",
            "Epoch 82/100\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.1696 - accuracy: 0.9623\n",
            "Epoch 83/100\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 0.1631 - accuracy: 0.9636\n",
            "Epoch 84/100\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 0.1573 - accuracy: 0.9636\n",
            "Epoch 85/100\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 0.1541 - accuracy: 0.9636\n",
            "Epoch 86/100\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 0.1549 - accuracy: 0.9636\n",
            "Epoch 87/100\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.1494 - accuracy: 0.9597\n",
            "Epoch 88/100\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 0.1441 - accuracy: 0.9623\n",
            "Epoch 89/100\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 0.1412 - accuracy: 0.9610\n",
            "Epoch 90/100\n",
            "25/25 [==============================] - 1s 29ms/step - loss: 0.1384 - accuracy: 0.9506\n",
            "Epoch 91/100\n",
            "25/25 [==============================] - 1s 48ms/step - loss: 0.1342 - accuracy: 0.9610\n",
            "Epoch 92/100\n",
            "25/25 [==============================] - 1s 45ms/step - loss: 0.1365 - accuracy: 0.9623\n",
            "Epoch 93/100\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.1335 - accuracy: 0.9610\n",
            "Epoch 94/100\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 0.1284 - accuracy: 0.9597\n",
            "Epoch 95/100\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.1255 - accuracy: 0.9662\n",
            "Epoch 96/100\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 0.1231 - accuracy: 0.9610\n",
            "Epoch 97/100\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 0.1220 - accuracy: 0.9584\n",
            "Epoch 98/100\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.1235 - accuracy: 0.9662\n",
            "Epoch 99/100\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 0.1181 - accuracy: 0.9584\n",
            "Epoch 100/100\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 0.1167 - accuracy: 0.9597\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7acedc281ea0>"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"shobhit\"\n",
        "text = \"chatbots\"\n",
        "import time\n",
        "for i in range(10):\n",
        "  # tokenize\n",
        "  t = tokenizer.texts_to_sequences([text])[0]\n",
        "  # padding\n",
        "  padded_t = pad_sequences([t], maxlen=max_len-1, padding=\"pre\")\n",
        "  # predict\n",
        "  pos = np.argmax(model.predict(padded_t))\n",
        "\n",
        "  for word, index in tokenizer.word_index.items():\n",
        "    if index == pos:\n",
        "      text = text + \" \" + word\n",
        "      print(text)\n",
        "      time.sleep(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WhpZDfOJg0pH",
        "outputId": "65249d1e-d925-4287-f6ea-00e0f71b5de4"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 563ms/step\n",
            "chatbots ml\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "chatbots ml based\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "chatbots ml based chatbots\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "chatbots ml based chatbots using\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "chatbots ml based chatbots using rasa\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "chatbots ml based chatbots using rasa to\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "chatbots ml based chatbots using rasa to improve\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "chatbots ml based chatbots using rasa to improve cost\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "chatbots ml based chatbots using rasa to improve cost efficiency\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "chatbots ml based chatbots using rasa to improve cost efficiency and\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rUC2aHcShxFZ"
      },
      "execution_count": 104,
      "outputs": []
    }
  ]
}